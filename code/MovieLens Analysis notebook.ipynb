{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc6d801f-3132-4378-b267-ff5a2ebd6598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, col, explode, split, avg, broadcast, spark_partition_id\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType, FloatType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define file paths\n",
    "movies_path = \"/FileStore/tables/movies.dat\"\n",
    "ratings_path = \"/FileStore/tables/ratings.dat\"\n",
    "users_path = \"/FileStore/tables/users.dat\"\n",
    "\n",
    "# Define Partial schema to reduce the amount of data read\n",
    "movies_schema = StructType([StructField(\"movieId\", IntegerType(), True),\n",
    "                            StructField(\"title\", StringType(), True),\n",
    "                            StructField(\"genre\", StringType(), True)])             \n",
    "\n",
    "ratings_schema = StructType([StructField(\"userId\", IntegerType(), True),\n",
    "                            StructField(\"movieId\", IntegerType(), True),\n",
    "                            StructField(\"rating\", FloatType(), True)])           \n",
    "\n",
    "users_schema = StructType([StructField(\"userId\", IntegerType(), True),\n",
    "                           StructField(\"age\", IntegerType(), True)])                 \n",
    "\n",
    "# Applying filters while reading to reduce the data been read\n",
    "movies_df = spark.read.csv(movies_path, sep=\"::\", schema=movies_schema, inferSchema=False).withColumn(\"Year\", regexp_extract(col(\"Title\"), r\"\\((\\d{4})\\)$\", 1)).filter(\"Year > 1989\")\n",
    "ratings_df = spark.read.csv(ratings_path, sep=\"::\", schema=ratings_schema, inferSchema=False)                            \n",
    "users_df = spark.read.csv(users_path, sep=\"::\", schema=users_schema, inferSchema=False).filter(\"age in (18,25,35,45)\")           # Write the data in parquet at this step for faster subsequent processing(can be used in a medallion architecture)\n",
    "\n",
    "#Exploding genre column since one movie is part of multiple genre\n",
    "exploded_movies_df = movies_df.withColumn(\"genre\",explode(split(\"genre\",\"\\|\")))\n",
    "\n",
    "joined_ratings_user_df = ratings_df.join(broadcast(users_df),[\"userId\"],\"inner\")                                                    #Broadcasting users_df & movies_df to avoid shuffle\n",
    "\n",
    "joined_movie_rating_user_df = joined_ratings_user_df.join(broadcast(exploded_movies_df),[\"movieId\"],\"inner\")                        #Check for skewness for specific combination of genre & year and Reparttion here on genre and year if needed  \n",
    "\n",
    "agg_result = joined_movie_rating_user_df.groupby(\"year\",\"genre\").agg(avg(\"rating\").alias(\"Avg_Rating\")).sortWithinPartitions(\"year\",\"genre\")    #Set shuffle partition if needed\n",
    "\n",
    "agg_result.write.parquet(\"/FileStore/tables/results\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdaa6894-d856-47bd-9842-2150a7a4228d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MovieLens Analysis notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
